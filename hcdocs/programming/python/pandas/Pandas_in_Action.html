<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>HC Docs</title>
        <style>
        body {
          font-family: sans-serif;
        }

        a {
          text-decoration: none;
          display: inline-block;
          color: #21c;
        }

        a:visited {
          color: #82a;
        }

        a.index {
          margin-bottom: 1rem;
        }

        h2, h3, h4 {
          margin-top: 2.75rem;
        }

        li {
          margin: 0.25rem 0;
        }

        pre {
          box-sizing: border-box;
          margin: 1rem;
          padding: 1rem;
          border: 1px solid #ccc;
          background-color: #ffefd5;
          border-radius: 0.8rem;
          overflow: auto;
          min-width: calc(100% - 2rem);
          font-size: 1rem;
        }

        code {
          padding: 0 0.2rem;
          color: #062;
          font-size: 1rem;
        }

        .hc-monospace {
          font-family: monospace;
        }

        .content {
          max-width: 820px;
          margin-left: auto;
          margin-right: auto;
        }

        table {
          border-collapse: collapse;
        }

        td {
          padding: 0.5rem 0.8rem;
          border: 1px solid #ccc;
        }
        </style>
    </head>
    <body>
      <div style="position: fixed; top: 0; padding: 0.5em; background-color: #fff;">
        <a href="javascript:history.back()">&#x1F519; bk</a>&nbsp;&nbsp;
        <a href="#top">&#x1F51D; top</a>&nbsp;&nbsp;
        <a href="index.html">&#x1F4C2; dir</a>&nbsp;&nbsp;
        <a href="../index.html">&#x23EB; up</a>
      </div>
      <div id="top">&nbsp;</div>
      <div class="content">


    <h3><a href="../../../index.html">home</a> / <a href="../../index.html">programming</a> / <a href="../index.html">python</a> / <a href="index.html">pandas</a></h3>
    
<h1>Pandas in Action, &copy; 2021</h1>

<h3>Contents</h3>

<ul>
  <li><a href="#part1">Part 1 Core pandas</a></li>
  <li><a href="#ch1">1 Introducing pandas</a></li>
  <li><a href="#ch2">2 The Series object</a></li>
  <li><a href="#ch3">3 Series methods</a></li>
  <li><a href="#ch4">4 The DataFrame object</a></li>
  <li><a href="#ch5">5 Filtering a DataFrame</a></li>
  <li><a href="#part2">Part 2 Applied pandas</a></li>
  <li><a href="#ch6">6 Working with text data</a></li>
  <li><a href="#ch7">7 MultiIndex DataFrames</a></li>
  <li><a href="#ch8">8 Reshaping and pivoting</a></li>
</ul>


<h2 id="part1">Part 1 Core pandas</h2>

<p>
  The two primary data structures are:
  <ul>
    <li>Series (one-dimensional). Can be thought of as a single column of data with an index made up of any type of object.</li>
    <li>DataFrame (two-dimensional)</li>
  </ul>
</p>

<p>
  This part covers the fundamentals of pandas.
</p>


<h2 id="ch1">1 Introducing pandas</h2>

<p>
  pandas is a library for data analysis. A library is a collection of code for solving problems in a specific field.
</p>

<p>
  Example of importing and sorting a CSV data set:
</p>

<pre>
populations = pd.read_csv("pop.csv")
populations.sort_values(by="Population", ascending=False)
</pre>

<p>
  When loading data without setting an index, a numeric index starting from 0 is automatically generated.
</p>

<pre>
pd.read_csv("movies.csv", index_col="Title")
</pre>

<p>
  <code>df.head(n)</code> and <code>df.tail(n)</code> extracts <code>n</code> rows from the start or end of <code>df</code>. If <code>n</code> is omitted, 5 rows are returned.
</p>

<ul>
  <li><code>len(df)</code> returns the number of rows.</li>
  <li><code>df.shape</code> returns a tuple of (rows, columns).</li>
  <li><code>df.size</code> returns the number of cells.</li>
  <li><code>df.dtypes</code> returns the data types of each column.</li>
</ul>

<p>
  To extract a row by its numeric order, use <code>df.iloc[499]</code>. (The index starts at 0, so this expression returns the 500th row.
</p>

<p>
  To extract a row by its index label (following the example above, the index is "Title"), use <code>df.loc["Sister Act"]</code>.
</p>

<p>
  <em>Note</em>: Index labels may be duplicated (in the Movies data set, "101 Dalmatians" appears twice, being the original and the remake).
</p>

<p>
  If possible, avoid duplicates in the index.
</p>

<h3>Sorting a DataFrame</h3>

<pre>
movies.sort_values(by="Year", ascending=False).head()

movies.sort_values(by=["Year", "Studio"], ascending=[False, True]).head()
</pre>

<p>
  To see the movies in alphabetical order, we can sort the index:
</p>

<pre>
movies.sort_index().head()
</pre>

<p>
  <strong>Example:</strong> Find out which studio had the greatest number of highest-grossing films. To solve this problem, we need to count the number of times each studio appears:
</p>

<pre>
movies["Studio"] # returns the Title and Studio

movies["Studio"].value_counts().head(10) # top 10 studios
</pre>

<h4>1.3.4 Filtering a column by one or more criteria</h4>

<pre>
movies[movies["Studio"] == "Universal"]

# or save the condition in a variable
released_by_universal = movies["Studio"] == "Universal"
movies[released_by_universal].head()

# define another condition and check movies that satisfy both
released_in_2015 = movies["Year"] == 2015
movies[released_by_universal & released_in_2015]

# use an 'or' conditional
movies[released_by_universal | released_in_2015]
</pre>

<p>
  Find movies released before 1965:
</p>

<pre>
movies[movies["Year"] < 1965]
</pre>

<p>
  Specify a range (both endpoints are included):
</p>

<pre>
movies[movies["Year"].between(1961, 1975)]
</pre>

<p>
  Check if the title contains a string:
</p>

<pre>
has_dark_in_title = movies.index.str.lower().str.contains("dark")
movies[has_dark_in_title]
</pre>

<h4>1.3.5 Grouping data</h4>

<p>
  Which studio had the highest total grosses across all films? A problem to be addressed is to convert the string values of Gross into a number (remove the dollar sign and commas). <strong>Note</strong>: the book passes <code>regex=False</code>, but it is already False by default.
</p>

<pre>
movies["Gross"] = (movies["Gross"]
    .str.replace("$", "")
    .str.replace(",", "")
    .astype(float)
) # parentheses are needed to make the expression multi-line
</pre>

<p>
  The average gross is <code>movies["Gross"].mean()</code>
</p>

<p>
  The process of bucketing the movies by studio is <em>grouping</em>.
</p>

<pre>
studios = movies.groupby("Studio")
</pre>

<p>
  The number of movies per studio is:
</p>

<pre>
studios["Gross"].count().sort_values(ascending=False).head()
</pre>

<p>
  Add the values of the Gross column and sort them:
</p>

<pre>
studios["Gross"].sum().sort_values(ascending=False).head()
</pre>

<h2 id="ch2">2 The Series object</h2>

<p>
  A <code>Series</code> is a one-dimensional labeled array for homogeneous data (all values are of the same data type).
</p>

<p>
  Each value in a Series has a <em>label</em> (an identifier we can use to locate the value).
</p>

<p>
  In addition, each value is assigned an <em>order</em> (a position in line). The order starts from 0.
</p>

<p>
  To access a value, either the label or its position may be used. A Series is like a combination of a Python list and dictionary. (A label acts like a dict key, while its order is an integer value that starts from 0).
</p>

<h4>2.1.2 Populating the Series with values</h4>

<p>
  The Series constructor accepts an iterable object whose values will populate the Series.
</p>

<pre>
ice_cream_flavors = [
    "Chocolate",
    "Strawberry",
    "Rum Raisin",
]

days_of_week = ("Mon", "Wed", "Fri", "Sat")
</pre>

<p>
  The term <em>index</em> describes both the collection of identifiers and an individual identifier.
</p>

<p>
  An index label assigned to a Series value may be any immutable data type (such as strings, tuples, and datetimes).
</p>

<p>
  The first two parameters of <code>Series()</code> is data and index. The following are equivalent:
</p>

<pre>
pd.Series(ice_cream_flavors, days_of_week)
pd.Series(data=ice_cream_flavors, index=days_of_week)
</pre>

<p>
  Indices may contain duplicates; however, it's best to ensure they are unique for better performance.
</p>

<p>
  The dtype for strings is <code>object</code>.
</p>

<p>
  Tuples may be used as values. The dtype will be <code>object</code>.
</p>

<h3>2.1.4 Creating a Series with missing values</h3>

<p>
  When pandas sees a missing value during an import, the value <code>np.nan</code> is used. <code>None</code> is converted to <code>np.nan</code>.
</p>

<p>
  Two <code>nan</code> values are not equal to each other. Use <code>np.isnan(x)</code> to check for <code>nan</code>.
</p>

<p>
  pandas converts numeric values from integers to floats if there's a <code>nan</code> value.
</p>

<h3>2.2 Creating a Series from Python objects</h3>

<p>
  A Series may be constructed from:
  <ul>
    <li>Lists and tuples: a numeric index is automatically created</li>
    <li>Dictionaries: keys become index labels.</li>
    <li>Sets: convert to a list first or use <code>sorted(set)</code></li>
    <li>NumPy <code>ndarray</code>: pass directly, such as <code>pd.Series(np.random.randint(1, 100, 5))</code></li>
  </ul>
</p>

<h3>2.3 Series attributes</h3>

<p>
  Some useful attributes of Series and related values are:
  <ul>
    <li><code>s.values</code></li>
    <li><code>type(s.values)</code></li>
    <li><code>s.index</code></li>
    <li><code>s.dtype</code></li>
    <li><code>s.size</code></li>
    <li><code>s.shape</code></li>
    <li><code>s.is_unique</code> (checks if all values are unique)</li>
    <li><code>s.index.is_unique</code></li>
    <li><code>s.is_monotonic</code></li>
  </ul>
</p>

<h3>2.5 Mathematical operations</h3>

<h4>2.5.1 Statistical operations</h4>

<pre>
numbers = pd.Series([1, 2, 3, np.nan, 4, 5])
numbers.count() # counts the number of non-null values
numbers.sum() # skipna=False forces the inclusion of missing values
numbers.product()
numbers.mean()
numbers.median()
numbers.std()
numbers.max()
numbers.min()
numbers.cumsum()
numbers.pct_change() # uses forward-fill to replace missing values with the last valid value
</pre>

<p>
  The <code>pad</code> and <code>ffill</code> are the same forward-fill strategy for the <code>fill_method</code> parameter.
</p>

<p>
  <code>bfill</code> is <em>backfill</em>. With this option, pandas replaces missing values with the next valid observation.
</p>

<p>
  <code>numbers.describe()</code> returns many statistics at once.
</p>

<p>
  <code>numbers.sample(n)</code> selects <code>n</code> values from the Series, in a random order.
</p>

<p>
  <code>numbers.unique()</code> returns a NumPy ndarray of unique values.
</p>

<p>
  <code>numbers.nunique()</code> returns the number of unique values.
</p>

<h4>2.5.2 Arithmetic operations</h4>

<p>
  Any operation with a nan results in a nan.
</p>

<p>
  Adding a Series and a scalar results in the scalar being added to every element.
</p>

<pre>
s + 3
# is the same as
s.add(3)
</pre>

<p>
  The other common operations are <code>sub, mul, div, floordiv, mod</code>
</p>

<h4>2.5.3 Broadcasting</h4>

<p>
  <em>Broadcasting</em> is the derivation of one array of values from another, like a radio broacast transmitting the same signal to listeners.
</p>

<p>
  Pandas uses shared index labels to align values across different data structures.
</p>

<h3>2.6 Passing the Series to Python's built-in functions</h3>

<p>
  <code>list(s)</code> and <code>dict(s)</code> return built-in Python objects.
</p>

<p>
  Like in Python, the <code>in</code> keyword checks if a value is present in the index. To check the values, use <code>"Los Angeles" in cities.values</code>. (In this example, the index is numeric).
</p>

<h2 id="ch3">3 Series methods</h2>

<p>
  To convert a one-column DataFrame to a Series, use the <code>.squeeze()</code> method. <code>read_csv()</code> defaults to creating a DataFrame, so it should be squeezed for the examples in this chapter.
</p>

<p>
  The index column of a CSV can be passed as an argument:
</p>

<pre>
pokemon = pd.read_csv("pokemon.csv", index_col="Pokemon").squeeze()
</pre>

<p>
  The resulting series is named after the value column (in the source file, "Type").
</p>

<p>
  To convert a column of datetimes, use the <code>parse_dates</code> parameter:
</p>

<pre>
google = pd.read_csv("google_stocks.csv", parse_dates=["Date"], index_col="Date").squeeze()
</pre>

<p>
  The <code>usecols</code> parameter defines which columns to read.
</p>

<pre>
battles = pd.read_csv("revolutionary_war.csv", index_col="Start Date", parse_dates=["Start Date"], usecols=["State", "Start Date"]).squeeze()
</pre>

<h3>3.2 Sorting a Series</h3>

<p>
  <code>google.sort_values()</code> returns a new Series with the values in ascending order (increasing in size).
</p>

<p>
  Capital letters will appear before lowercase ones.
</p>

<p>
  To sort from largest to smallest, pass <code>ascending=False</code> to sort_values.
</p>

<p>
  <code>na_position</code> may be <code>"last"</code> (default) or <code>"first"</code>.
</p>

<p>
  The <code>dropna</code> method returns a Series with missing values removed (the index is not targeted).
</p>

<pre>
battles.dropna().sort_values()
</pre>

<h4>3.2.2 Sorting by index with the sort_index method</h4>

<p>
  Like sorting by value, <code>sort_index</code> also accepts an <code>ascending</code> parameter.
</p>

<pre>
pokemon.sort_index(ascending=False)
</pre>

<p>
  A missing date is represented by a <code>NaT</code> value. It maintains data integrity with the index's datetime type. Its actual type is <code>class 'pandas._libs.tslibs.nattype.NaTType'</code>.
</p>

<p>
  <code>nsmallest(n), nlargest(n)</code> return the n smallest and n largest values. <strong>Note</strong>: these methods do not work on Series of strings.
</p>

<pre>
google.nlargest()
</pre>

<h3>3.3 Overwriting a Series with the inplace parameter</h3>

<p>
  Many pandas methods accept an <code>inplace</code> parameter, that when passed with <code>True</code>, will modify the object with the given method. Otherwise, the Series is not affected.
</p>

<pre>
battles.sort_values(inplace=True)
</pre>

<p>
  In-place operations do not conserve memory. Pandas always creates a duplicate, then assigns (or not) the existing variable. If possible, avoid making in-place operations.
</p>

<p>
  A better alternative is to assign the altered value to a new variable, such as <code>sorted_battles</code>.
</p>

<h3>3.4 Counting values with the value_counts method</h3>

<p>
  <code>s.value_counts()</code> groups the values into buckets and counts the number of elements in each bucket.
</p>

<pre>
pokemon.value_counts()
</pre>

<p>
  The number of values shown by <code>value_counts</code> is the same as the number of <code>nunique()</code>.
</p>

<p>
  To get the frequencies of each value (percentage of the total), pass <code>normalize=True</code>.
</p>

<p>
  To round values, use the <code>round(decimals)</code> method:
</p>

<pre>
(pokemon.value_counts(normalize=True) * 100).round(2)
</pre>

<p>
  When dealing with continuous values (such as the Google stock price data), it is more useful to define buckets to divide the data into.
</p>

<pre>
buckets = [0, 200, 400, 600, 800, 1000, 1200, 1400] # or list(range(0, 1401, 200))
google.value_counts(bins=buckets)
</pre>

<p>
  Pass <code>sort=False</code> to sort by the buckets. By default, the sorting is by counts, in descending order.
</pre>

<p>
  By default, the left endpoint is not included and the right endpoint is.
</p>

<p>
  Passing <code>bins=n</code> will automatically generate <code>n</code> bins to divide the values into.
</p>

<p>
  To count nan values with value_counts, pass <code>dropna=False</code>.
</p>

<p>
  An index can also be used as the input to <code>value_counts</code>:
</p>

<pre>
battles.index.value_counts()
</pre>

<h3>3.5 Invoking a function on every Series value with apply</h3>

<p>
  Functions in Python are first-class objects. They can be stored in lists, assigned to variables, passed to other functions, and be returned by other functions.
</p>

<pre>
google.apply(round)

def round_to_one_decimal(n):
    return round(n, 1)

google.apply(round_to_one_decimal)
</pre>

<p>
  A Series index can be converted to a series in order to run the methods described above:
</p>

<pre>
battles.index.to_series().dropna().apply(get_wkdy).value_counts()
</pre>

<h2 id="ch4">4 The DataFrame object</h2>

<p>
  A DataFrame is a two-dimensional table with rows and columns. Similar to a Series, each row of a DataFrame is assigned an index label and index position.
</p>

<p>
  In addition, each column is assigned a label and position.
</p>

<p>
  Two points of reference is needed to retrieve a value from the dataset&mdash;a row and a column.
</p>

<h4>4.1.1 Creating a DataFrame from a dictionary</h4>

<p>
  A suitable input for a DataFrame is a Python dict whose values are lists. The keys become column names and values become column values.
</p>

<pre>
city_data = {
    "City": ["New York", "Paris", "Barcelona", "Rome"],
    "Country": ["USA", "FRA", "ESP", "ITA"],
    "Population": [8600000, 2141000, 5515000, 2873000],
}

cities = pd.DataFrame(city_data)
</pre>

<p>
  Column headers are like a second index. Similar to a Series' index, each column has both an index label and a numeric index position.
</p>

<p>
  To swap the column headers with index labels, use the <code>transpose()</code> method or access the <code>T</code> attribute.
</p>

<p>
  cities.transpose()
  # or
  cities.T
</p>

<h4>Creating a DataFrame from a NumPy ndarray</h4>

<p>
  The DataFrame constructor accepts a NumPy ndarray:
</p>

<pre>
np.random.seed(232)
random_data = np.random.randint(1, 101, [8, 20]) # 101 is excluded
# generates 8 rows and 20 columns
</pre>

<p>
  Labels may be set manually when constructing the DataFrame:
</p>

<pre>
row_labels = ["Morning", "Afternoon", "Evening"]
column_labels = ["Mon", "Tue", "Wed", "Thu", "Fri"]
values = np.random.randint(25, 36, [3, 5])
temperatures = pd.DataFrame(values, index=row_labels, columns=column_labels)
</pre>

<h3>4.2 Similarities between Series and DataFrames</h3>

<p>
  As before, <code>read_csv()</code> is used to load CSV data. Also, the <code>parse_dates</code> parameter is used to convert strings to datetimes.
</p>

<pre>
nba = pd.read_csv("nba.csv", parse_dates=["Birthday"], date_format="%m/%d/%y")
</pre>

<p>
  A DataFrame is like a collection of Series that share a common index. Each column of a DataFrame may have its own dtype; check <code>df.dtypes</code>.
</p>

<p>
  To count the number of columns storing each data type:
</p>

<pre>
nba.dtypes.value_counts()
</pre>

<p>
  <code>nba.index</code> holds the row labels.
</p>

<p>
  <code>nba.columns</code> holds the column labels.
</p>

<p>
  Other useful DataFrame attributes are:
</p>

<ul>
  <li><code>df.ndim</code> is the number of dimensions. For DataFrames, it's 2.</li>
  <li><code>df.shape</code> is a tuple (rows, columns).</li>
  <li><code>df.size</code> is the total number of values (including nans).</li>
  <li><code>df.count()</code> returns a Series of the counts of present values.</li>
</ul>

<p>
  The max and min methods return a Series with the max or min value for each column.
</p>

<p>
  To find out the n players with the largest salary, evaluate <code>nba.nlargest(3, "Salary")</code>.
</p>

<p>
  It is equivalent to <code>nba.nlargest(n=4, columns=["Salary"])</code>.
</p>

<p>
  To sum only numeric columns:
</p>

<pre>
nba.sum(numeric_only=True)
</pre>

<p>
  Additional statistical measurements are: <code>mean, median, mode, std</code>. Similar to Series, there is also a <code>describe()</code> method.
</p>

<h4>4.3.1 Sorting by a single column</h4>

<pre>
nba.sort_values("Name")
# or
nba.sort_values(by="Name")
</pre>

<p>
  To sort in descending order, pass <code>ascending=False</code>.
</p>

<h4>4.3.2 Sorting by multiple columns</h4>

<pre>
nba.sort_values(["Team", "Name"])
</pre>

<p>
  To control the order of each column, pass a list of ascending values:
</p>

<pre>
nba.sort_values(by=["Team", "Salary"], ascending=[True, False])
</pre>

<h3>4.4 Sorting by index</h3>

<p>
  After performing a sort and reassigning a DataFrame, it still has its numeric index, but in a different order (as a result of the sort). It is possible to restore it to its original order:
</p>

<pre>
nba.sort_index()
</pre>

<h4>4.4.2 Sorting by column index</h4>

<p>
  To sort the columns in order, pass <code>axis=1</code> or <code>axis="columns"</code>.
</p>

<pre>
nba.sort_index(axis=1)
</pre>

<h3>4.5 Setting a new index</h3>

<p>
  <code>set_index()</code> returns a new DataFrame with a new column set as the index.
</p>

<pre>
nba.set_index("Name")
# or
nba.set_index(keys="Name")
</pre>

<h3>4.6 Selecting columns and rows from a DataFrame</h3>

A DataFrame is a collection of Series objects with a common index.

<h4>4.6.1 Selecting a single column from a DataFrame</h4>

<p>
  Each column is available as an attribute, such as <code>nba.Salary</code> or <code>nba["Salary"]</code> (useful if there's a space in the column name)</p>. For consistency, it's better to always use the square bracket syntax.
</p>

<h4>4.6.2 Selecting multiple columns from a DataFrame</h4>

<p>
  To extract multiple columns, declare a pair of square brackets and place a list of the desired columns in a list:
</p>

<pre>
nba[["Salary", "Birthday"]]
</pre>

<p>
  To select columns based on their data types, use <code>select_dtypes</code>. It accepts the parameters <code>include</code> and <code>exclude</code>. They cannot overlap.
</p>

<pre>
nba.select_dtypes(include="object")
nba.select_dtypes(exclude=["object", "int"])
</pre>

<h3>4.7 Selecting rows from a DataFrame</h3>

<p>
  Rows may be extracted by index label or position.
</p>

<h4>4.7.1 Extracting rows by index label</h4>

<p>
  The <code>loc</code> attribute extracts a row by label.
</p>

<p>
  Attributes such as <code>loc</code> are called <em>accessors</em> because they access a piece of data. The result is a Series with the row's values.
</p>

<pre>
# must reassign the index first
nba = nba.set_index("Name").sort_index()
nba.loc["LeBron James"]
</pre>

<p>
  We can pass a list of labels between the square brackets to extract multiple rows.
</p>

<pre>
nba.loc[["Kawhi Leonard", "Paul George"]]
</pre>

<p>
  <code>loc</code> accepts a starting value and ending value, separated by a colon, which is similar to Python's list slicing syntax (it's recommended to sort the index first). Endpoints are included, if they exist:
</p>

<pre>
nba.loc["Otto Porter":"Patrick Beverley"]
nba.loc["O":"Q"]
nba.loc["Zach Collins":]
nba.loc[:"B"]
</pre>

<h4>4.7.2 Extracting rows by index position</h4>

<p>
  <code>iloc</code> is an accessor that extracts rows by index position, which is useful if the position of the rows has any significance. In this case, the slice syntax excludes the right endpoint. Negative numbers may be used in the slice syntax, like in regular Python syntax.
</p>

<pre>
nba.iloc[300]
nba.iloc[[100, 200, 300]]
nba.iloc[0:10:2]
</pre>

<h4>4.7.3 Extracting values from specific columns</h4>

<p>
  Both loc and iloc accept a second argument representing the column(s) to extract:
</p>

<pre>
nba.loc["Giannis Antetokounmpo", "Team"]
nba.loc["James Harden", ["Position", "Birthday"]]
nba.loc[
    ["Russell Westbrook", "Anthony Davis"],
    ["Team", "Salary"]
]
</pre>

<p>
  When using a slice for the column names, the start and end points must be in the order in which they appear in the DataFrame.
</p>

<h4>at and iat</h4>

<p>
  When we know that we want to extract a single value, <code>at</code> and <code>iat</code> are faster because they use optimized searching algorithms:
</p>

<pre>
nba.at["Austin Rivers", "Birthday"]
nba.iat[263, 1]
</pre>

<h3>4.8 Extracting values from Series</h3>

<p>
  loc, iloc, at, and iat are available on Series objects as well.
</p>

<pre>
nba["Salary"].loc["Amir Coffey"]
</pre>

<h3>4.9 Renaming columns or rows</h3>

<p>
  The rename method of a DataFrame allows you to reassign column names. It is not an in-place operation. The result must be reassigned to the original variable:
</p>

<pre>
nba.rename(columns={"Salary": "Pay"})
nba.rename(index={"Aaron Gordon": "Mr. Gordon"})
</pre>

<h3>4.10 Resetting an index</h3>

<p>
  Using set_index discards the current index. In order to preserve the index, we must first evaluate <code>reset_index</code> and then use set_index with the new index:
</p>

<pre>
# after running nba.set_index("Team")
nba.reset_index().head()
nba.set_index("Team")
</pre>

<p>
  One advantage of not using the <code>inplace</code> parameter is that many method calls can be chained:
</p>

<pre>
nba = nba.reset_index().set_index("Team")
</pre>

<h2 id="ch5">5 Filtering a DataFrame</h2>

<p>
  <em>Filtering</em> is the process of extracting a subset of rows using condition(s) and criteria.
</p>

<h3>5.1 Optimizing a data set for memory use</h3>

<p>
  The "best" data type for a column of a data set is the one that consumes the least memory or provides the most utility.
</p>

<p>
  The <code>info()</code> method displays a list of the columns, their data types, count of missing values and memory consumption.
</p>

<pre>
employees = pd.read_csv("employees.csv", parse_dates=["Start Date"])
employees.info()
</pre>

<h4>5.1.1 Converting data types with the astype method</h4>

<p>
  The <code>astype</code> method converts a Series' values to a different data type. It accepts either the data type or a string with its name.
</p>

<pre>
employees["Mgmt"].astype(bool)
</pre>

<p>
  Updating a DataFrame column works similarly to setting a key-value pair in a dict. A new column can also be created with this syntax.
</p>

<pre>
employees["Mgmt"] = employees["Mgmt"].astype(bool)
</pre>

<p>
  <strong>Note:</strong> The last row's empty Mgmt value became True.
</p>

<p>
  nan values cannot be converted to integer. To solve this problem, invoke the <code>fillna()</code> method before <code>astype()</code>. It's a good idea to always use <code>fillna</code> before changing a column's type.
</p>

<p>
  Pandas includes a special data type called a <em>category</em>. It works well for a column consisting of a small number of unique values, such as gender, weekdays, and income groups.
</p>

<p>
  The <code>nunique()</code> method outputs the number of unique values in each column. It ignores nan values by default.
</p>

<pre>
employees["Gender"].astype("category")
</pre>

<h3>5.2 Filtering by a single condition</h3>

<p>
  To compare every Series entry with a constant value, write:
</p>

<pre>
Series == value
# for example:
employees["First Name"] == "Maria"
</pre>

<p>
  The result is a Series of Booleans. To extract only the rows with a True value, write:
</p>

<pre>
employees[employees["First Name"] == "Maria"]
</pre>

<p>
  To avoid writing the DataFrame's name twice, the Boolean Series may be assigned to a temporary variable that is passed to the outer brackets:
</p>

<pre>
marias = employees["First Name"] == "Maria"
employees[marias]
</pre>

<p>
  Remember to use two equal signs <code>==</code> and for "not equal", the operator <code>!=</code>. If a single equal sign is written by accident, all First Names will be assigned to "Maria".
</p>

<p>
  A nan value is considered to be unequal to a string (such as "Finance").
</p>

<p>
  Like regular Python, it is not necessary to write <code>== True</code> if a column is already made of Booleans.
</p>

<p>
  Mathematical conditions may use &lt; and &gt; signs:
</p>

<pre>
employees[employees["Salary"] &gt; 149_000]
</pre>

<h3>5.3 Filtering by multiple conditions</h3>

<p>
  Create independent Boolean Series and apply the logical criteria between them.
</p>

<h4>5.3.1 The AND condition</h4>

<p>
  Consider finding all female employees in "Business Dev":
</p>

<pre>
is_female = employees["Gender"] == "Female"
in_business_dev = employees["Team"] == "Business Dev"

employees[is_female &amp; in_business_dev].head()
</pre>

<p>
  <strong>Note:</strong> using <code>and</code> instead of <code>&amp;</code> will not work.
</p>

<h4>5.3.2 The OR condition</h4>

<p>
  When combining conditions with OR, use the pipe symbol <code>|</code>. At least one condition has to be true.
</p>

<pre>
earning_below_40k = employees["Salary"] < 40_000
started_after_2015 = employees["Start Date"] > "2015-01-01"
employees[earning_below_40k | started_after_2015]
</pre>

<h4>5.3.3 Inversion with ~</h4>

<p>
  The tilde symbol <code>~</code> inverts the Boolean values in a Series. Enclose a condition in parentheses, and write the tilde outside them.
</p>

<pre>
~my_series
employees[~(employees["Salary"] >= 100_000)].head()
</pre>

<p>
  Comparisons (==, !=, <, <=, >, >=) may be done with methods:
</p>

<pre>
employees["Team"].eq("Marketing")
employees["Team"].ne("Marketing")
employees["Salary"].lt(100_000)
employees["Salary"].le(100_000)
employees["Salary"].gt(100_000)
employees["Salary"].ge(100_000)
</pre>

<h3>5.4 Filtering by condition</h3>

<h4>5.4.1 The isin method</h4>

<p>
  The <code>isin</code> method accepts an iterable of elements (list, tuple, Series, etc.) and returns a Boolean Series:
</p>

<pre>
all_star_teams = ["Sales", "Legal", "Marketing"]
in_all_star_teams = employees["Team"].isin(all_star_teams)
employees[in_all_star_teams].head()
</pre>

<h4>5.4.2 The between method</h4>

<p>
  The between method accepts a lower and upper bound. The lower bound is inclusive, and the upper bound is exclusive. The parameters are called <code>left, right</code>. Datetimes and strings may be passed as arguments.
</p>

<pre>
between_80k_and_90k = employees["Salary"].between(80_000, 90_000)
employees[between_80k_and_90k].head()
</pre>

<h4>5.4.3 The isnull and notnull methods</h4>

<p>
  Missing text and numeric values are NaNs while missing datetime values are NaTs.
</p>

<pre>
employees["Team"].isnull().head()
employees["Team"].notnull().head()
</pre>

<h4>5.4.4 Dealing with null values</h4>

<p>
  The <code>dropna</code> method removes rows that hold any NaN values. If <code>how="all"</code> is passed, only rows that are missing all values are removed. The default value is "any".
</p>

<pre>
employees.dropna()
employees.dropna(how="all")
</pre>

<p>
  The <code>subset</code> parameter can be used to target rows with a missing value in a specific column (or columns).
</p>

<pre>
employees.dropna(subset=["Gender"])
employees.dropna(subset=["Gender", "First Name"])
</pre>

<p>
  The <code>thresh</code> parameter specifies a minimum threshold of non-null values that a row must have to be kept.
</p>

<pre>
employees.dropna(thresh=4).head()
</pre>

<h3>5.5 Dealing with duplicates</h3>

<h4>5.5.1 The duplicated method</h4>

<p>
  The <code>duplicated</code> method returns a Boolean Series that identifies values that were previously encountered. The first value is not marked True. Only the remaining duplicates are.
</p>

<p>
  <strong>Note:</strong> NaNs are considered to be a unique value.
</p>

<pre>
employees.["Team"].duplicated().head()
</pre>

<p>
  By passing <code>keep="last"</code>, the last occurrence is marked as the nonduplicate.
</p>

<p>
  Suppose we want to extract one employee from each team. One way to do so is to pull out the first row for each unique team. By inverting the Series of duplicates, we get a Series in which True is the first time a Team is encountered:
</p>

<pre>
first_one_in_team = ~employees["Team"].duplicated()
employees[first_one_in_team]
</pre>

<h4>5.5.2 The drop_duplicates method</h4>

<p>
  By default, <code>drop_duplicates</code> removes rows where all their values have been encountered before.
</p>

<p>
  To target certain columns, pass <code>subset=["Column Name"]</code>. The argument <code>keep="last"</code> may also be passed.
</p>

<pre>
employees.drop_duplicates(subset=["Team"])
</pre>

<p>
  If <code>keep=False</code> is passed, all rows with duplicate values are excluded. In other words, only rows with values that occur exactly once are kept.
</p>

<h2 id="part2">Part 2 Applied pandas</h2>

<p>
  The chapters in this part cover how to tackle common problems in data analysis.
</p>

<h2 id="ch6">6 Working with text data</h2>

<p>
  The process of cleaning data is called <em>wrangling</em> or <em>munging</em>.
</p>

<h3>6.1 Letter casing and whitespace</h3>

<pre>
inspections = pd.read_csv("chicago_food_inspections.csv")
</pre>

<p>
  The <code>values</code> attribute of a Series is the underlying NumPy ndarray storing the values.
</p>

<p>
  A Series' <code>str</code> attribute exposes a StringMethods object, which contains many methods for working with strings.
</p>

<p>
  strip, lstrip, and rstrip remove whitespace from a string.
</p>

<p>
  We overwrite the Name column with the whitespace-stripped values:
</p>

<pre>
inspections["Name"] = inspections["Name"].str.strip()
</pre>

<p>
  To apply <code>strip</code> to all columns, use a loop:
</p>

<pre>
for column in inspections.columns:
    inspections[column] = inspections[column].str.strip()
</pre>

<p>
  str.lower() lowercases all characters. str.upper() uppercases all characters. str.capitalize() capitalizes the first letter of each string. str.title() capitalizes each word's first letter.
</p>

<h3>6.2 String slicing</h3>

<p>
  DataFrame's <code>replace</code> method will replace all occurrences of one value with another. The first parameter, to_replace, sets the value to search for, and the second parameter, value, specifies what to replace each occurrence of it with. (it's simpler to call replace without the keywords, and it works like Python's str.replace)
</p>

<h3>6.3 String slicing</h3>

<p>
  str.slice(start_index, end_index) or str[start_index:end_index] works like standard Python's string slicing.
</p>

<h3>6.4 Boolean methods</h3>

<p>
  str.contains checks for a substring's inclusion in a Series value.
</p>

<pre>
has_pizza = inspections["Name"].str.lower().str.contains("pizza").head()
inspections[has_pizza]
</pre>

<p>
  str.startswith() and str.endswith() checks the substring and where it occurs.
</p>

<h3>6.5 Splitting strings</h3>

<pre>
customers = pd.read_csv("customers.csv")
</pre>

<p>
  str.split() converts a Series of strings into a Series of lists. The Python default separator is None. An optional second arguments specifies how many times the string should be split.
</p>

<p>
  str.get(0) pulls out the first element of each list. A negative argument may be passed, starting from the end.
</p>

<p>
  If str.split is passed <code>expand=True</code>, it will return a new DataFrame instead of a Series of lists.
</p>

<p>
  <strong>Warning:</strong> If some rows contain more values than the rest, the rows with fewer elements will have None in the respective columns. Passing a limit to how many splits are performed may work in some cases.
</p>

<p>
  To assign column names to the resulting DataFrame:
</p>

<pre>
customers[["First Name", "Last Name"]] = customers["Name"].str.split(" ", 1, expand=True)
</pre>

<p>
  To drop a column:
</p>

<pre>
customers = customers.drop(labels="Name", axis="columns")

# or
customers = customers.drop("Name", axis=1)

# to drop multiple columns
customers = customers.drop(["Name", "Address"], axis=1)

# using del
del customers["Address"]
</pre>

<h3>6.7 A note on regular expressions</h3>

<p>
  To use regexes in str methods, pass <code>regex=True</code>.
</p>

<h2 id="ch7">7 MultiIndex DataFrames</h2>

<p>
  One way of looking at the meaning of dimensionality (the fact that Series is one-dimensional and that DataFrames are two-dimensional) is the number of reference points needed to extract a value from that data structure.
</p>

<p>
  One reference point is needed for a Series, and two are needed for a DataFrame.
</p>

<p>
  With a MultiIndex, any number of dimensions is supported.
</p>

<p>
  Consider a table with a stock's symbol, a date, and price. To find a price, we need both the symbol and the date. A MultiIndex storing the symbol and date columns would suit this data set well.
</p>

<p>
  MultiIndexes are also ideal for hierarchical data, where one column's values are a subcategory of another column's values. For example, Fruit &gt; Apple, Banana and Vegetable &gt; Broccoli, Carrot.
</p>

<h3>7.1 The MultiIndex object</h3>

<p>
  Remember that a Python tuple is an immutable data structure that holds a sequence of values in order. Imagine tuples serving as a DataFrame's index labels.
</p>

<p>
  A MultiIndex object is an index (a storage container) in which each label can store mutiple pieces of data.
</p>

<p>
  A MultiIndex object can be created independently of a Series or DataFrame. There is a MultiIndex class available as a top-level attribute of pandas. It includes a <code>from_tuples</code> class method that instantiates a MultiIndex from a list of tuples.
</p>

<pre>
addresses = [
    ("8809 Flair Square", "Toddside", "IL", "37206"),
    ("9901 Austin Street", "Toddside", "IL", "37206"),
    ("905 Hogan Quarter", "Franklin", "IL", "37206"),
]

pd.MultiIndex.from_tuples(addresses)
</pre>

<p>
  The collection of tuple values at the same position forms a <em>level</em> of the MultiIndex. Each level of the MultiIndex can be assigned a name when using from_tuples:
</p>

<pre>
row_index = pd.MultiIndex.from_tuples(
    addresses,
    names = ["Street", "City", "State", "Zip"]
)
</pre>

<p>
  To attach a MultiIndex to a DataFrame, the easiest way is passing it in the constructor's <code>index</code> parameter:
</p>

<pre>
data = [
    ['A', 'B+'],
    ['C+', 'C'],
    ['D', 'A-'],
]

columns = ['Schools', 'Cost of Living']

area_grades = pd.DataFrame(data=data, index=row_index, columns=columns)
</pre>

<p>
  This DataFrame has a MultiIndex on its row axis. Each row's label holds four values (street, city, state, zip code).
</p>

<p>
  The DataFrame's column headers are stored in an index object as well:
</p>

<pre>
area_grades.columns

# Index(['Schools', 'Cost of Living'], dtype='object')
</pre>

<p>
  It is possible to have a MultiIndex as the column index as well:
</p>

<pre>
column_index = pd.MultiIndex.from_tuples(
    [
        ("Culture", "Restaurants"),
        ("Culture", "Museums"),
        ("Services", "Police"),
        ("Services", "Schools"),
    ]
)

# with the new column structure, the data needs to be 3 x 4:
data = [
    ['C', 'B-', 'D', 'A-'],
    ['A-', 'C-', 'B+', 'B'],
    ['B+', 'A-', 'C-', 'C+'],
]

pd.DataFrame(data=data, index=row_index, columns=column_index)
</pre>

<h3>7.2 MultiIndex DataFrames</h3>

<p>
  When creating a DataFrame from a CSV with multiple header rows or columns for the row idex, pass the column/row indices to the index_col and header parameters:
</p>

<pre>
neighborhoods = pd.read_csv(
    "neighborhoods.csv", index_col=[0, 1, 2], header=[0, 1]
)

# describe the DataFrame
neighborhoods.info()
neighborhoods.index
neighborhoods.columns

neighborhoods.index.names

neighborhoods.index.get_level_values(1) # or ("City")
</pre>

<p>
  Assign names to columns:
</p>

<pre>
neighborhoods.columns.names = ["Category", "Subcategory"]

neighborhoods.columns.get_level_values(0)
</pre>

<p>
  A MultiIndex will carry over to new objects derived from a data set. The index can switch axes depending on the operation. If we invoke nunique on neighborhoods, the DataFrame's column MultiIndex will swap axes and become the row's MultiIndex in the resulting Series.
</p>

<h3>7.3 Sorting a MultiIndex</h3>

<p>
  Calling sort_index() will sort all levels in ascending order, outside in. To vary the sorting at each level:
</p>

<pre>
neighborhoods.sort_index(ascending=[True, False, False])
</pre>

<p>
  To sort a level by itself:
</p>

<pre>
neighborhoods.sort_index(level=1) # or level="City"
neighborhoods.sort_index(level=[1, 2], ascending=[True, False])
# or level=["City", "Street"]
</pre>

<p>
  Sorting accepts an axis parameter (with a default value of 0, or row index). To sort the columns, we pass axis=1 or axis="columns".
</p>

<h3>7.4 Selecting with a MultiIndex</h3>

<p>
  Consider this 2 x 2 DataFrame:
</p>

<pre>
data = [
    [1, 2],
    [3, 4]
]

df = pd.DataFrame(data=data, index=['A', 'B'], columns=['X', 'Y'])
</pre>

<p>
  To extract a column, we can use the square bracket syntax:
</p>

<pre>
df['X']
</pre>

<h4>7.4.1 Extracting one or more columns</h4>

<p>
  If a single value is passed in square brackets, pandas will look for it in the outermost level of the columns' MultiIndex: <code>neighborhoods['Services']</code>
</p>

<p>
  To target multiple levels of a MultiIndex, use a tuple:
</p>

<pre>
neighborhoods[("Services", "Schools")]
</pre>

<p>
  To extract multiple columns, pass a list of tuples (the list may be defined in an intermediate variable for clarity):
</p>

<pre>
neighborhoods[[("Services", "Schools"), ("Culture", "Museums")]]
</pre>

<h4>7.4.2 Extracting one or more rows with loc</h4>

<p>
  The <code>loc</code> accessor extracts by index label, and <code>iloc</code> extracts by index position. In the 2 x 2 example above, <code>df.loc['A']</code> selects the first row.
</p>

<p>
  Similar to selecting a column that has a MultiIndex, pass a tuple to loc to get a specific row (any depth may be passed):
</p>

<pre>
neighborhoods.loc[("TX", "Kingchester", "534 Gordon Falls")]
</pre>

<p>
  The second argument to loc declares which column(s) to extract:
</p>

<pre>
neighborhoods.loc["CA", "Culture"]
</pre>

<p>
  To avoid ambiguity between row levels and a column label, wrap all arguments for a given index inside a tuple, remembering that a one-element tuple needs a trailing comma:
</p>

<pre>
neighborhoods.loc[("CA", "Dustinmouth"), ("Services",)]
</pre>

<p>
  Use a list to store multiple keys, and a tuple to store the components of a multilevel key.
</p>

<p>
  To select sequential rows, use the list-slicing syntax:
</p>

<pre>
neighborhoods["NE":"NH"]
neighborhoods[("NE", "Shawnchester"):("NH", "North Latoya")]
neighborhoods[("NE", "Shawnchester"):("NH",)]
</pre>

<h4>7.4.3 Extracting one or more rows with iloc</h4>

<p>
  iloc accepts two arguments to represent the row and column indices.
</p>

<p>
  To pull out multiple rows, wrap their index positions in a list:
</p>

<pre>
neighborhoods.iloc[[25, 30, 32, 50]]
</pre>

<p>
  Slicing with iloc excludes the endpoint: <code>neighborhoods.iloc[25:30]</code> returns 5 rows.
</p>

<p>
  A slice may also declare which columns to pull out. Negative indices may also be passed.
</p>

<pre>
neighborhoods.iloc[25:30, 1:3]
neighborhoods.iloc[-4:, -2:]
</pre>

<p>
  <strong>Note:</strong> It is not possible to index across consecutive MultiIndex levels with iloc. It serves as a strict positional indexer that does not regard the structure of the DataFrame at all.
</p>

<h3>7.5 Cross-sections</h3>

<p>
  The <code>xs</code> method extracts rows by providing a value for <em>one</em> MultiIndex level. We pass the key parameter as the value to look for, and the level parameter as the numeric position or the name of the index level in which to look for the value:
</p>

<pre>
neighborhoods.xs(key="Lake Nicole", level=1)
neighborhoods.xs(key="Lake Nicole", level="City")
</pre>

<p>
  To search using columns, pass "columns" or 1 as the axis parameter:
</p>

<pre>
neighborhoods.xs(key="Museums", level="Subcategory", axis=1)
neighborhoods.xs(key="Museums", level="Subcategory", axis="columns")
</pre>

<p>
  We can also provide the xs method with keys across nonconsecutive MultiIndex levels by passing them in a tuple:
</p>

<pre>
neighborhoods.xs(key=('AK', '238 Andrew Rue'), level=['State', 'Street'])
</pre>

<h3>7.6 Manipulating the Index</h3>

<h4>7.6.1 Resetting the index</h4>

<p>
  <code>reorder_levels</code> rearranges the MultiIndex levels in a specified order:
</p>

<pre>
new_order = ["City", "State", "Street"]
neighborhoods.reorder_levels(order=new_order)
neighborhoods.reorder_levels(order=[1, 0, 2])
</pre>

<p>
  reset_index() returns a new DataFrame that integrates the former MultiIndex levels as columns. The new index is the standard numeric one. By default, the new columnns' Subcategory value is an empty string.
</p>

<p>
  To set a particular column, pass the col_level parameter:
</p>

<pre>
neighborhoods.reset_index(col_level="Subcategory")
neighborhoods.reset_index(col_level=1)
</pre>

<p>
  Passing an argument to col_fill replaces the Category value:
</p>

<pre>
neighborhoods.reset_index(col_fill="Address", col_level="Subcategory")
</pre>

<p>
  Passing a name to the levels parameter moves a single index level to a regular DataFrame column:
</p>

<pre>
neighborhoods.reset_index(level="Street")
</pre>

<p>
  Move multiple index levels by passing them in a list:
</p>

<pre>
neighborhoods.reset_index(level=["Street", "City"])
</pre>

<p>
  To remove a level, pass <code>drop=True</code>
</p>

<pre>
neighborhoods.reset_index(level="Street", drop=True)
</pre>

<h4>7.6.2 Setting the index</h4>

<p>
  Evaluate this line to set up the DataFrame for this section:
</p>

<pre>
neighborhoods = neighborhoods.reset_index()
</pre>

<p>
  set_index sets one or more columns as the new index:
</p>

<pre>
neighborhoods.set_index(keys="City")
neighborhoods.set_index(keys=("Culture", "Museums"))
</pre>

<p>
  To create a MultiIndex, pass a list with multiple columns:
</p>

<pre>
neighborhoods.set_index(keys=["State", "City"])
</pre>

<h2 id="ch8">8 Reshaping and pivoting</h2>

<p>
  <em>Reshaping</em> a data set means manipulating it into a different shape, one that tells a better story than its original presentation.
</p>

<h3>8.1 Wide vs. narrow data</h3>

<p>
  A <em>narrow</em> data set is also called <em>long</em> or <em>tall</em>. It grows down, increasing its height. The other kind, <em>wide</em> data, increases in width. Consider:
</p>

<pre>
   Weekday  Miami  New York
0   Monday    100        65
1  Tuesday    105        70
</pre>

<p>
  There are three variables: weekdays, temperatures, and cities. This data set is wide, because adding more cities will increase its width.
</p>

<p>
  A narrow format makes it easier to manipulate existing data and to add new records:
</p>

<pre>
   Weekday      City  Temperature
0   Monday     Miami          100
1   Monday  New York           65
2  Tuesday     Miami          105
3  Tuesday  New York           70
4  Tuesday   Chicago           58
</pre>

<h3>8.2 Creating a pivot table from a DataFrame</h3>

<p>
  <code>sales_by_employee.csv</code> is a list of business deals at a fictional company.
</p>

<pre>
sales = pd.read_csv("sales_by_employee.csv", parse_dates=["Date"])
</pre>

<h4>8.2.1 The pivot_table method</h4>

<p>
  A <em>pivot table</em> aggregates a column's values and groups the results by using other columns' values.
</p>

<p>
  An <em>aggregate</em> describes a summary computation that involves multiple values. Common aggregations are average, sum, median, and count.
</p>

<p>
  The steps to create a pivot table are:
</p>

<ol>
  <li>Select the column(s) whose values we want to aggregate</li>
  <li>Choose the aggregation operation to apply to the column(s)</li>
  <li>Select the column(s) whose values will group the aggregated data into categories</li>
  <li>Determine whether to place the groups on the row axis, column axis, or both</li>
</ol>

<p>
  The <code>pivot_table</code> method's <code>index</code> parameter accepts the column whose values will make up the pivot table's index labels. Pandas will use the unique values from that column to group the results. The default aggregation operation is to compute the average (mean). It can be declared with the <code>aggfunc</code> parameter.
</p>

<pre>
sales.pivot_table(index="Date")
</pre>

<p>
  To limit the columns to be aggregated, pass the column(s) to the <code>values</code> parameter as a string or list of strings. In this example, we want to know the total for each day.
</p>

<pre>
sales.pivot_table(index="Date", values="Revenue", aggfunc="sum")
</pre>

<p>
  Now, to separate the sales by employee, we pass "Name" to the <code>columns</code> parameter:
</p>

<pre>
sales.pivot_table(index="Date", columns="Name", values="Revenue", aggfunc="sum")
</pre>

<p>
  Use <code>fill_value=0</code> to replace NaNs with zeros.
</p>

<p>
  Passing <code>margins=True</code> adds totals for each row and column. <strong>Note:</strong> datetimes are converted to strings because of the new "All" value. <code>margins_name="Custom name"</code> changes from "All" to the given value.
</p>

<p>
  <code>aggfunc</code> can also be: max, min, std, median, size (same as count).
</p>

<p>
  It is possible to pass a list or dict to <code>aggfunc</code>:
</p>

<pre>
aggfunc=["sum", "count"]

aggfunc={"Revenue": "min", "Expenses": "max"}
</pre>

<p>
  <code>index</code> can also be a list, resulting in a MultiIndex.
</p>

<pre>
index=["Name", "Date"]
</pre>

<h3>8.3 Stacking and unstacking index levels</h3>

</div>
<br>
<hr>
<div style="padding-left: 0.5em; background-color: #fff;">
  <a href="javascript:history.back()">&#x1F519; Back</a>&nbsp;&nbsp;&nbsp;
  <a href="#top">&#x1F51D; Top</a>&nbsp;&nbsp;&nbsp;
  <a href="index.html">&#x1F4C2; Dir list</a>&nbsp;&nbsp;&nbsp;
  <a href="../index.html">&#x23EB; Up</a>&nbsp;&nbsp;&nbsp;
</div>
<br><br><br>
    </body>
</html>

